{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem Set 3_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUuXSA9MttFs576tRF3bGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljanastas/PADP-9200-Ethics-and-Algorithms/blob/master/Problem_Set_3_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1EURENbExAl",
        "colab_type": "text"
      },
      "source": [
        "# [POLS 9500]: Problem Set 3 SOLUTIONS\n",
        "\n",
        "\n",
        "# The data\n",
        "The data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors’ physical appearance. (This is aslightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors.\n",
        "  \n",
        "# Predicting student ratings using random forests\n",
        "\n",
        "For this problem set we will be training a random forest model to predict student ratings of 'very good' or 'excellent'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-upsVQsz8wM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "d676767f-4111-49ad-82f1-bddbe476a227"
      },
      "source": [
        "head(evals)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  score rank         ethnicity    gender language age cls_perc_eval\n",
              "1 4.7   tenure track minority     female english  36  55.81395     \n",
              "2 4.1   tenure track minority     female english  36  68.80000     \n",
              "3 3.9   tenure track minority     female english  36  60.80000     \n",
              "4 4.8   tenure track minority     female english  36  62.60163     \n",
              "5 4.6   tenured      not minority male   english  59  85.00000     \n",
              "6 4.3   tenured      not minority male   english  59  87.50000     \n",
              "  cls_did_eval cls_students cls_level ⋯ cls_credits  bty_f1lower bty_f1upper\n",
              "1 24            43          upper     ⋯ multi credit 5           7          \n",
              "2 86           125          upper     ⋯ multi credit 5           7          \n",
              "3 76           125          upper     ⋯ multi credit 5           7          \n",
              "4 77           123          upper     ⋯ multi credit 5           7          \n",
              "5 17            20          upper     ⋯ multi credit 4           4          \n",
              "6 35            40          upper     ⋯ multi credit 4           4          \n",
              "  bty_f2upper bty_m1lower bty_m1upper bty_m2upper bty_avg pic_outfit pic_color\n",
              "1 6           2           4           6           5       not formal color    \n",
              "2 6           2           4           6           5       not formal color    \n",
              "3 6           2           4           6           5       not formal color    \n",
              "4 6           2           4           6           5       not formal color    \n",
              "5 2           2           3           3           3       not formal color    \n",
              "6 2           2           3           3           3       not formal color    "
            ],
            "text/latex": "A data.frame: 6 × 21\n\\begin{tabular}{r|lllllllllllllllllllll}\n  & score & rank & ethnicity & gender & language & age & cls\\_perc\\_eval & cls\\_did\\_eval & cls\\_students & cls\\_level & ⋯ & cls\\_credits & bty\\_f1lower & bty\\_f1upper & bty\\_f2upper & bty\\_m1lower & bty\\_m1upper & bty\\_m2upper & bty\\_avg & pic\\_outfit & pic\\_color\\\\\n  & <dbl> & <fct> & <fct> & <fct> & <fct> & <int> & <dbl> & <int> & <int> & <fct> & ⋯ & <fct> & <int> & <int> & <int> & <int> & <int> & <int> & <dbl> & <fct> & <fct>\\\\\n\\hline\n\t1 & 4.7 & tenure track & minority     & female & english & 36 & 55.81395 & 24 &  43 & upper & ⋯ & multi credit & 5 & 7 & 6 & 2 & 4 & 6 & 5 & not formal & color\\\\\n\t2 & 4.1 & tenure track & minority     & female & english & 36 & 68.80000 & 86 & 125 & upper & ⋯ & multi credit & 5 & 7 & 6 & 2 & 4 & 6 & 5 & not formal & color\\\\\n\t3 & 3.9 & tenure track & minority     & female & english & 36 & 60.80000 & 76 & 125 & upper & ⋯ & multi credit & 5 & 7 & 6 & 2 & 4 & 6 & 5 & not formal & color\\\\\n\t4 & 4.8 & tenure track & minority     & female & english & 36 & 62.60163 & 77 & 123 & upper & ⋯ & multi credit & 5 & 7 & 6 & 2 & 4 & 6 & 5 & not formal & color\\\\\n\t5 & 4.6 & tenured      & not minority & male   & english & 59 & 85.00000 & 17 &  20 & upper & ⋯ & multi credit & 4 & 4 & 2 & 2 & 3 & 3 & 3 & not formal & color\\\\\n\t6 & 4.3 & tenured      & not minority & male   & english & 59 & 87.50000 & 35 &  40 & upper & ⋯ & multi credit & 4 & 4 & 2 & 2 & 3 & 3 & 3 & not formal & color\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 6 × 21\n\n| <!--/--> | score &lt;dbl&gt; | rank &lt;fct&gt; | ethnicity &lt;fct&gt; | gender &lt;fct&gt; | language &lt;fct&gt; | age &lt;int&gt; | cls_perc_eval &lt;dbl&gt; | cls_did_eval &lt;int&gt; | cls_students &lt;int&gt; | cls_level &lt;fct&gt; | ⋯ ⋯ | cls_credits &lt;fct&gt; | bty_f1lower &lt;int&gt; | bty_f1upper &lt;int&gt; | bty_f2upper &lt;int&gt; | bty_m1lower &lt;int&gt; | bty_m1upper &lt;int&gt; | bty_m2upper &lt;int&gt; | bty_avg &lt;dbl&gt; | pic_outfit &lt;fct&gt; | pic_color &lt;fct&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 4.7 | tenure track | minority     | female | english | 36 | 55.81395 | 24 |  43 | upper | ⋯ | multi credit | 5 | 7 | 6 | 2 | 4 | 6 | 5 | not formal | color |\n| 2 | 4.1 | tenure track | minority     | female | english | 36 | 68.80000 | 86 | 125 | upper | ⋯ | multi credit | 5 | 7 | 6 | 2 | 4 | 6 | 5 | not formal | color |\n| 3 | 3.9 | tenure track | minority     | female | english | 36 | 60.80000 | 76 | 125 | upper | ⋯ | multi credit | 5 | 7 | 6 | 2 | 4 | 6 | 5 | not formal | color |\n| 4 | 4.8 | tenure track | minority     | female | english | 36 | 62.60163 | 77 | 123 | upper | ⋯ | multi credit | 5 | 7 | 6 | 2 | 4 | 6 | 5 | not formal | color |\n| 5 | 4.6 | tenured      | not minority | male   | english | 59 | 85.00000 | 17 |  20 | upper | ⋯ | multi credit | 4 | 4 | 2 | 2 | 3 | 3 | 3 | not formal | color |\n| 6 | 4.3 | tenured      | not minority | male   | english | 59 | 87.50000 | 35 |  40 | upper | ⋯ | multi credit | 4 | 4 | 2 | 2 | 3 | 3 | 3 | not formal | color |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A data.frame: 6 × 21</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>score</th><th scope=col>rank</th><th scope=col>ethnicity</th><th scope=col>gender</th><th scope=col>language</th><th scope=col>age</th><th scope=col>cls_perc_eval</th><th scope=col>cls_did_eval</th><th scope=col>cls_students</th><th scope=col>cls_level</th><th scope=col>⋯</th><th scope=col>cls_credits</th><th scope=col>bty_f1lower</th><th scope=col>bty_f1upper</th><th scope=col>bty_f2upper</th><th scope=col>bty_m1lower</th><th scope=col>bty_m1upper</th><th scope=col>bty_m2upper</th><th scope=col>bty_avg</th><th scope=col>pic_outfit</th><th scope=col>pic_color</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>⋯</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>4.7</td><td>tenure track</td><td>minority    </td><td>female</td><td>english</td><td>36</td><td>55.81395</td><td>24</td><td> 43</td><td>upper</td><td>⋯</td><td>multi credit</td><td>5</td><td>7</td><td>6</td><td>2</td><td>4</td><td>6</td><td>5</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>4.1</td><td>tenure track</td><td>minority    </td><td>female</td><td>english</td><td>36</td><td>68.80000</td><td>86</td><td>125</td><td>upper</td><td>⋯</td><td>multi credit</td><td>5</td><td>7</td><td>6</td><td>2</td><td>4</td><td>6</td><td>5</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>3.9</td><td>tenure track</td><td>minority    </td><td>female</td><td>english</td><td>36</td><td>60.80000</td><td>76</td><td>125</td><td>upper</td><td>⋯</td><td>multi credit</td><td>5</td><td>7</td><td>6</td><td>2</td><td>4</td><td>6</td><td>5</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>4.8</td><td>tenure track</td><td>minority    </td><td>female</td><td>english</td><td>36</td><td>62.60163</td><td>77</td><td>123</td><td>upper</td><td>⋯</td><td>multi credit</td><td>5</td><td>7</td><td>6</td><td>2</td><td>4</td><td>6</td><td>5</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>4.6</td><td>tenured     </td><td>not minority</td><td>male  </td><td>english</td><td>59</td><td>85.00000</td><td>17</td><td> 20</td><td>upper</td><td>⋯</td><td>multi credit</td><td>4</td><td>4</td><td>2</td><td>2</td><td>3</td><td>3</td><td>3</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>4.3</td><td>tenured     </td><td>not minority</td><td>male  </td><td>english</td><td>59</td><td>87.50000</td><td>35</td><td> 40</td><td>upper</td><td>⋯</td><td>multi credit</td><td>4</td><td>4</td><td>2</td><td>2</td><td>3</td><td>3</td><td>3</td><td>not formal</td><td>color</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI0ZugiDJAFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First load the evaluation dataset named \"evals\" \n",
        "\n",
        "download.file(\"http://www.openintro.org/stat/data/evals.RData\", destfile = \"evals.RData\")\n",
        "load(\"evals.RData\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK4cxf0IS4uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Also install the following packages\n",
        "\n",
        "install.packages('ranger')\n",
        "install.packages('caret')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM_jlrRt__qW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "71c5a401-51ad-4c92-833d-d83c4d6cbcc8"
      },
      "source": [
        "table(target)/length(target)\n",
        "table(target)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target\n",
              "        0         1 \n",
              "0.3218143 0.6781857 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target\n",
              "  0   1 \n",
              "149 314 "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPYYjiZRArm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "552ac9a7-077d-42e1-d907-d9fcce839675"
      },
      "source": [
        "# Tenured, # of tenured professors who have \"good\" vs. \"bad\" evaluations\n",
        "table(target[rank == \"tenured\"])\n",
        "\n",
        "# tenure track, # of tenure-track professors who have \"good\" vs. \"bad\" evaluations\n",
        "table(target[rank == \"tenure track\"])\n",
        "\n",
        "# teaching track, # of teaching track professors who have \"good\" vs. \"bad\" evaluations\n",
        "table(target[rank == \"teaching\"])\n",
        "\n",
        "# Proportions\n",
        "166/(166+87) # Tenured\n",
        "\n",
        "74/(34+74) # Tenure track\n",
        "\n",
        "74/(28+74) # Teaching"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "  0   1 \n",
              " 87 166 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              " 0  1 \n",
              "34 74 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              " 0  1 \n",
              "28 74 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.6561265"
            ],
            "text/latex": "0.656126482213439",
            "text/markdown": "0.656126482213439",
            "text/html": [
              "0.656126482213439"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.6851852"
            ],
            "text/latex": "0.685185185185185",
            "text/markdown": "0.685185185185185",
            "text/html": [
              "0.685185185185185"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.7254902"
            ],
            "text/latex": "0.725490196078431",
            "text/markdown": "0.725490196078431",
            "text/html": [
              "0.725490196078431"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DV1qV0XJYBm",
        "colab_type": "text"
      },
      "source": [
        "## Variable names and description\n",
        "\n",
        "* `score`\taverage professor evaluation score: (1) very unsatisfactory - (5) excellent.\n",
        "* `rank`\trank of professor: teaching, tenure track, tenured.\n",
        "* `ethnicity`\tethnicity of professor: not minority, minority.\n",
        "* `gender`\tgender of professor: female, male.\n",
        "* `language`\tlanguage of school where professor received education: english or non-english.\n",
        "* `age`\tage of professor.\n",
        "* `cls_perc_eval`\tpercent of students in class who completed evaluation.\n",
        "* `cls_did_eval`\tnumber of students in class who completed evaluation.\n",
        "* `cls_students`\ttotal number of students in class.\n",
        "* `cls_level`\tclass level: lower, upper.\n",
        "* `cls_profs`\tnumber of professors teaching sections in course in sample: single, multiple.\n",
        "* `cls_credits`\tnumber of credits of class: one credit (lab, PE, etc.), multi credit.\n",
        "* `bty_f1lower`\tbeauty rating of professor from lower level female: (1) lowest - (10) highest.\n",
        "* `bty_f1upper`\tbeauty rating of professor from upper level female: (1) lowest - (10) highest.\n",
        "* `bty_f2upper`\tbeauty rating of professor from second upper level female: (1) lowest - (10) highest.\n",
        "* `bty_m1lower`\tbeauty rating of professor from lower level male: (1) lowest - (10) highest.\n",
        "* `bty_m1upper`\tbeauty rating of professor from upper level male: (1) lowest - (10) highest.\n",
        "* `bty_m2upper`\tbeauty rating of professor from second upper level male: (1) lowest - (10) highest.\n",
        "* `bty_avg`\taverage beauty rating of professor.\n",
        "* `pic_outfit`\toutfit of professor in picture: not formal, formal.\n",
        "* `pic_color`\tcolor of professor’s picture: color, black & white"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba062QL2Ou24",
        "colab_type": "text"
      },
      "source": [
        "# Question 1 Training a Random Forest Classifier [50 Points]\n",
        "\n",
        "Train a random forest classifier using the \"ranger\" package that will enable you to predict whether an instructor recieves a rating of \"very good\" (4) or \"excellent\" (5) using all of the remaining variables in the dataset.\n",
        "\n",
        "Please use a 75/25 train/test split. \n",
        "\n",
        "Report: \n",
        "* The confusion matrix\n",
        "* Accuracy, precision, recall and F1 statistic of the trained random forest model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkFwyUIhQTDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "library(ranger)\n",
        "library(caret)\n",
        "\n",
        "attach(evals)\n",
        "\n",
        "target = ifelse(score>=4,1,0)\n",
        "##### YOUR CODE HERE ###################################\n",
        "\n",
        "# Set seed for rng\n",
        "set.seed(33) # Super-sneaky Masonic number \n",
        "\n",
        "# Create the set of randomized indices\n",
        "training.pct = 0.75\n",
        "index = sample(nrow(evals), training.pct * nrow(evals)) \n",
        "\n",
        "# Create the training and test data\n",
        "evals.train = evals[index,] # Training data features\n",
        "evals.test = evals[-index,] # Test data features*\n",
        "#*Note: be sure to remove \"score\" from the test data\n",
        "\n",
        "target.train = target[index] # 75% training data set target\n",
        "target.test = target[-index] # 25% test set target\n",
        "\n",
        "# Update training and test data\n",
        "evals.train = data.frame(evals.train,target.train)\n",
        "\n",
        "# Part 1: Training the random forest algorithm on the training data.\n",
        "\n",
        "rf.evals.train <- ranger(target.train ~ . -score, data = evals.train, \n",
        "               importance='impurity',\n",
        "               write.forest=TRUE, # Writes out the trees\n",
        "               probability=TRUE)  # The algorithm will produce the probability in the output\n",
        "\n",
        "##### YOUR CODE HERE ###################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mNcwGHEXscE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "4c819b66-42bb-444e-97e3-2632c6aaffef"
      },
      "source": [
        "# Aside, may be useful to check dimensionality of training and test to confirm\n",
        "# Did it work?\n",
        "dim(evals.train)\n",
        "dim(evals.test)\n",
        "\n",
        "head(evals.test) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 347  22"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 347\n\\item 22\n\\end{enumerate*}\n",
            "text/markdown": "1. 347\n2. 22\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>347</li><li>22</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 116  22"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 116\n\\item 22\n\\end{enumerate*}\n",
            "text/markdown": "1. 116\n2. 22\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>116</li><li>22</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   rank         ethnicity    gender language age cls_perc_eval cls_did_eval\n",
              "5  tenured      not minority male   english  59  85.00000      17          \n",
              "16 tenured      not minority female english  40  90.00000      18          \n",
              "19 tenure track not minority female english  31  90.90909      40          \n",
              "20 tenure track not minority female english  31  79.16666      38          \n",
              "22 tenure track not minority female english  31  88.13559      52          \n",
              "23 tenure track not minority female english  31  56.32184      49          \n",
              "   cls_students cls_level cls_profs cls_credits  bty_f1lower bty_f1upper\n",
              "5  20           upper     multiple  multi credit 4           4          \n",
              "16 20           upper     multiple  multi credit 2           5          \n",
              "19 44           upper     multiple  multi credit 7           9          \n",
              "20 48           upper     multiple  multi credit 7           9          \n",
              "22 59           upper     multiple  multi credit 7           9          \n",
              "23 87           upper     single    multi credit 7           9          \n",
              "   bty_f2upper bty_m1lower bty_m1upper bty_m2upper bty_avg pic_outfit pic_color\n",
              "5  2           2           3           3           3.000   not formal color    \n",
              "16 4           3           3           2           3.167   not formal color    \n",
              "19 9           7           6           6           7.333   not formal color    \n",
              "20 9           7           6           6           7.333   not formal color    \n",
              "22 9           7           6           6           7.333   not formal color    \n",
              "23 9           7           6           6           7.333   not formal color    "
            ],
            "text/latex": "A data.frame: 6 × 20\n\\begin{tabular}{r|llllllllllllllllllll}\n  & rank & ethnicity & gender & language & age & cls\\_perc\\_eval & cls\\_did\\_eval & cls\\_students & cls\\_level & cls\\_profs & cls\\_credits & bty\\_f1lower & bty\\_f1upper & bty\\_f2upper & bty\\_m1lower & bty\\_m1upper & bty\\_m2upper & bty\\_avg & pic\\_outfit & pic\\_color\\\\\n  & <fct> & <fct> & <fct> & <fct> & <int> & <dbl> & <int> & <int> & <fct> & <fct> & <fct> & <int> & <int> & <int> & <int> & <int> & <int> & <dbl> & <fct> & <fct>\\\\\n\\hline\n\t5 & tenured      & not minority & male   & english & 59 & 85.00000 & 17 & 20 & upper & multiple & multi credit & 4 & 4 & 2 & 2 & 3 & 3 & 3.000 & not formal & color\\\\\n\t16 & tenured      & not minority & female & english & 40 & 90.00000 & 18 & 20 & upper & multiple & multi credit & 2 & 5 & 4 & 3 & 3 & 2 & 3.167 & not formal & color\\\\\n\t19 & tenure track & not minority & female & english & 31 & 90.90909 & 40 & 44 & upper & multiple & multi credit & 7 & 9 & 9 & 7 & 6 & 6 & 7.333 & not formal & color\\\\\n\t20 & tenure track & not minority & female & english & 31 & 79.16666 & 38 & 48 & upper & multiple & multi credit & 7 & 9 & 9 & 7 & 6 & 6 & 7.333 & not formal & color\\\\\n\t22 & tenure track & not minority & female & english & 31 & 88.13559 & 52 & 59 & upper & multiple & multi credit & 7 & 9 & 9 & 7 & 6 & 6 & 7.333 & not formal & color\\\\\n\t23 & tenure track & not minority & female & english & 31 & 56.32184 & 49 & 87 & upper & single   & multi credit & 7 & 9 & 9 & 7 & 6 & 6 & 7.333 & not formal & color\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 6 × 20\n\n| <!--/--> | rank &lt;fct&gt; | ethnicity &lt;fct&gt; | gender &lt;fct&gt; | language &lt;fct&gt; | age &lt;int&gt; | cls_perc_eval &lt;dbl&gt; | cls_did_eval &lt;int&gt; | cls_students &lt;int&gt; | cls_level &lt;fct&gt; | cls_profs &lt;fct&gt; | cls_credits &lt;fct&gt; | bty_f1lower &lt;int&gt; | bty_f1upper &lt;int&gt; | bty_f2upper &lt;int&gt; | bty_m1lower &lt;int&gt; | bty_m1upper &lt;int&gt; | bty_m2upper &lt;int&gt; | bty_avg &lt;dbl&gt; | pic_outfit &lt;fct&gt; | pic_color &lt;fct&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 5 | tenured      | not minority | male   | english | 59 | 85.00000 | 17 | 20 | upper | multiple | multi credit | 4 | 4 | 2 | 2 | 3 | 3 | 3.000 | not formal | color |\n| 16 | tenured      | not minority | female | english | 40 | 90.00000 | 18 | 20 | upper | multiple | multi credit | 2 | 5 | 4 | 3 | 3 | 2 | 3.167 | not formal | color |\n| 19 | tenure track | not minority | female | english | 31 | 90.90909 | 40 | 44 | upper | multiple | multi credit | 7 | 9 | 9 | 7 | 6 | 6 | 7.333 | not formal | color |\n| 20 | tenure track | not minority | female | english | 31 | 79.16666 | 38 | 48 | upper | multiple | multi credit | 7 | 9 | 9 | 7 | 6 | 6 | 7.333 | not formal | color |\n| 22 | tenure track | not minority | female | english | 31 | 88.13559 | 52 | 59 | upper | multiple | multi credit | 7 | 9 | 9 | 7 | 6 | 6 | 7.333 | not formal | color |\n| 23 | tenure track | not minority | female | english | 31 | 56.32184 | 49 | 87 | upper | single   | multi credit | 7 | 9 | 9 | 7 | 6 | 6 | 7.333 | not formal | color |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A data.frame: 6 × 20</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>rank</th><th scope=col>ethnicity</th><th scope=col>gender</th><th scope=col>language</th><th scope=col>age</th><th scope=col>cls_perc_eval</th><th scope=col>cls_did_eval</th><th scope=col>cls_students</th><th scope=col>cls_level</th><th scope=col>cls_profs</th><th scope=col>cls_credits</th><th scope=col>bty_f1lower</th><th scope=col>bty_f1upper</th><th scope=col>bty_f2upper</th><th scope=col>bty_m1lower</th><th scope=col>bty_m1upper</th><th scope=col>bty_m2upper</th><th scope=col>bty_avg</th><th scope=col>pic_outfit</th><th scope=col>pic_color</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>5</th><td>tenured     </td><td>not minority</td><td>male  </td><td>english</td><td>59</td><td>85.00000</td><td>17</td><td>20</td><td>upper</td><td>multiple</td><td>multi credit</td><td>4</td><td>4</td><td>2</td><td>2</td><td>3</td><td>3</td><td>3.000</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>tenured     </td><td>not minority</td><td>female</td><td>english</td><td>40</td><td>90.00000</td><td>18</td><td>20</td><td>upper</td><td>multiple</td><td>multi credit</td><td>2</td><td>5</td><td>4</td><td>3</td><td>3</td><td>2</td><td>3.167</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>tenure track</td><td>not minority</td><td>female</td><td>english</td><td>31</td><td>90.90909</td><td>40</td><td>44</td><td>upper</td><td>multiple</td><td>multi credit</td><td>7</td><td>9</td><td>9</td><td>7</td><td>6</td><td>6</td><td>7.333</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>20</th><td>tenure track</td><td>not minority</td><td>female</td><td>english</td><td>31</td><td>79.16666</td><td>38</td><td>48</td><td>upper</td><td>multiple</td><td>multi credit</td><td>7</td><td>9</td><td>9</td><td>7</td><td>6</td><td>6</td><td>7.333</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>22</th><td>tenure track</td><td>not minority</td><td>female</td><td>english</td><td>31</td><td>88.13559</td><td>52</td><td>59</td><td>upper</td><td>multiple</td><td>multi credit</td><td>7</td><td>9</td><td>9</td><td>7</td><td>6</td><td>6</td><td>7.333</td><td>not formal</td><td>color</td></tr>\n",
              "\t<tr><th scope=row>23</th><td>tenure track</td><td>not minority</td><td>female</td><td>english</td><td>31</td><td>56.32184</td><td>49</td><td>87</td><td>upper</td><td>single  </td><td>multi credit</td><td>7</td><td>9</td><td>9</td><td>7</td><td>6</td><td>6</td><td>7.333</td><td>not formal</td><td>color</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vyabuIaZgSB",
        "colab_type": "text"
      },
      "source": [
        "## Report the confusion matrix along with accuracy, precision and recall of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3CDwA9dEk8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "af976b98-a6c1-4565-84c2-653fe498f34f"
      },
      "source": [
        "# Scratch work\n",
        "head(rf_probs$predictions)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     [,1]      [,2]     \n",
              "[1,] 0.6367261 0.3632739\n",
              "[2,] 0.7192530 0.2807470\n",
              "[3,] 0.8812111 0.1187889\n",
              "[4,] 0.8686730 0.1313270\n",
              "[5,] 0.8717452 0.1282548\n",
              "[6,] 0.6396206 0.3603794"
            ],
            "text/latex": "A matrix: 6 × 2 of type dbl\n\\begin{tabular}{ll}\n\t 0.6367261 & 0.3632739\\\\\n\t 0.7192530 & 0.2807470\\\\\n\t 0.8812111 & 0.1187889\\\\\n\t 0.8686730 & 0.1313270\\\\\n\t 0.8717452 & 0.1282548\\\\\n\t 0.6396206 & 0.3603794\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 6 × 2 of type dbl\n\n| 0.6367261 | 0.3632739 |\n| 0.7192530 | 0.2807470 |\n| 0.8812111 | 0.1187889 |\n| 0.8686730 | 0.1313270 |\n| 0.8717452 | 0.1282548 |\n| 0.6396206 | 0.3603794 |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A matrix: 6 × 2 of type dbl</caption>\n",
              "<tbody>\n",
              "\t<tr><td>0.6367261</td><td>0.3632739</td></tr>\n",
              "\t<tr><td>0.7192530</td><td>0.2807470</td></tr>\n",
              "\t<tr><td>0.8812111</td><td>0.1187889</td></tr>\n",
              "\t<tr><td>0.8686730</td><td>0.1313270</td></tr>\n",
              "\t<tr><td>0.8717452</td><td>0.1282548</td></tr>\n",
              "\t<tr><td>0.6396206</td><td>0.3603794</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  [1] 0.6367261 0.7192530 0.8812111 0.8686730 0.8717452 0.6396206 0.8469611\n",
              "  [8] 0.8978968 0.8931079 0.9496143 0.6993375 0.8737492 0.9108953 0.9379714\n",
              " [15] 0.9321749 0.9237836 0.9665288 0.6507571 0.8838813 0.4619072 0.5777747\n",
              " [22] 0.6810333 0.5314336 0.8463852 0.7867952 0.9054579 0.9386730 0.5164537\n",
              " [29] 0.6264813 0.6401504 0.6349535 0.6957564 0.2718390 0.7092286 0.7022627\n",
              " [36] 0.5052079 0.5314024 0.6817802 0.5047213 0.4740460 0.7320802 0.6221368\n",
              " [43] 0.5392365 0.8931603 0.4227089 0.3253383 0.5219452 0.5211492 0.4722071\n",
              " [50] 0.9814929 0.9064246 0.7436889 0.8510516 0.5027445 0.2625381 0.7121444\n",
              " [57] 0.6719929 0.5186902 0.6010179 0.9373556 0.8875389 0.7318960 0.7304214\n",
              " [64] 0.7033143 0.9168365 0.8643483 0.7890616 0.5533857 0.5701802 0.5366603\n",
              " [71] 0.6328159 0.6914598 0.8341881 0.8584048 0.4380898 0.8354883 0.8042883\n",
              " [78] 0.4660115 0.3977298 0.4670369 0.4481242 0.7978952 0.3694730 0.8056325\n",
              " [85] 0.9703929 0.9282873 0.9698270 0.9831405 0.3579921 0.5113921 0.9178143\n",
              " [92] 0.3738421 0.6049025 0.5213381 0.7523583 0.7068262 0.8399508 0.5236930\n",
              " [99] 0.5281684 0.8593222 0.7436586 0.6391245 0.9003437 0.8941384 0.8865008\n",
              "[106] 0.5187558 0.5113778 0.1538438 0.4151190 0.7095389 0.7672641 0.8571697\n",
              "[113] 0.3663444 0.3892921 0.2571885 0.8829717"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 0.636726062826063\n\\item 0.719253030303031\n\\item 0.881211111111111\n\\item 0.868673015873016\n\\item 0.871745238095238\n\\item 0.639620634920635\n\\item 0.846961111111111\n\\item 0.897896825396825\n\\item 0.893107936507936\n\\item 0.949614285714286\n\\item 0.699337545787546\n\\item 0.873749206349206\n\\item 0.910895310245311\n\\item 0.937971428571429\n\\item 0.932174908424909\n\\item 0.923783577533578\n\\item 0.966528815628816\n\\item 0.650757142857143\n\\item 0.883881257631258\n\\item 0.461907215007215\n\\item 0.577774675324675\n\\item 0.681033333333333\n\\item 0.531433577533578\n\\item 0.846385225885226\n\\item 0.786795238095238\n\\item 0.905457936507937\n\\item 0.938673015873016\n\\item 0.516453676878677\n\\item 0.626481257631258\n\\item 0.640150377400378\n\\item 0.63495347985348\n\\item 0.695756421356421\n\\item 0.271838961038961\n\\item 0.709228571428572\n\\item 0.702262698412698\n\\item 0.505207936507936\n\\item 0.531402380952381\n\\item 0.681780158730159\n\\item 0.504721284271284\n\\item 0.474046031746032\n\\item 0.732080158730158\n\\item 0.622136752136752\n\\item 0.539236507936508\n\\item 0.893160317460317\n\\item 0.422708891108891\n\\item 0.325338256188256\n\\item 0.521945238095238\n\\item 0.521149206349206\n\\item 0.472207142857143\n\\item 0.981492857142857\n\\item 0.906424603174603\n\\item 0.743688888888889\n\\item 0.851051587301588\n\\item 0.502744516594517\n\\item 0.262538095238095\n\\item 0.712144444444444\n\\item 0.671992857142857\n\\item 0.518690170940171\n\\item 0.601017948717949\n\\item 0.937355555555555\n\\item 0.887538888888889\n\\item 0.731896031746032\n\\item 0.730421428571429\n\\item 0.703314285714286\n\\item 0.916836507936508\n\\item 0.864348268398268\n\\item 0.789061616161616\n\\item 0.553385714285714\n\\item 0.570180158730159\n\\item 0.536660317460318\n\\item 0.632815873015873\n\\item 0.691459816207185\n\\item 0.834188095238095\n\\item 0.858404761904761\n\\item 0.438089754689754\n\\item 0.835488347763348\n\\item 0.804288347763348\n\\item 0.466011507936508\n\\item 0.397729761904762\n\\item 0.467036904761905\n\\item 0.448124206349206\n\\item 0.797895238095238\n\\item 0.369473015873016\n\\item 0.80563253968254\n\\item 0.970392857142857\n\\item 0.928287301587301\n\\item 0.969826984126984\n\\item 0.983140476190476\n\\item 0.357992063492063\n\\item 0.511392063492063\n\\item 0.917814285714286\n\\item 0.373842063492063\n\\item 0.604902453102453\n\\item 0.521338095238095\n\\item 0.752358297258297\n\\item 0.70682619047619\n\\item 0.839950793650794\n\\item 0.523692998667999\n\\item 0.528168395493396\n\\item 0.859322222222222\n\\item 0.743658585858586\n\\item 0.639124458874458\n\\item 0.900343650793651\n\\item 0.894138387635756\n\\item 0.886500793650794\n\\item 0.518755847953216\n\\item 0.511377777777778\n\\item 0.153843795093795\n\\item 0.415119047619048\n\\item 0.709538888888889\n\\item 0.767264141414141\n\\item 0.857169658119658\n\\item 0.366344444444445\n\\item 0.389292063492064\n\\item 0.257188455988456\n\\item 0.88297172096909\n\\end{enumerate*}\n",
            "text/markdown": "1. 0.636726062826063\n2. 0.719253030303031\n3. 0.881211111111111\n4. 0.868673015873016\n5. 0.871745238095238\n6. 0.639620634920635\n7. 0.846961111111111\n8. 0.897896825396825\n9. 0.893107936507936\n10. 0.949614285714286\n11. 0.699337545787546\n12. 0.873749206349206\n13. 0.910895310245311\n14. 0.937971428571429\n15. 0.932174908424909\n16. 0.923783577533578\n17. 0.966528815628816\n18. 0.650757142857143\n19. 0.883881257631258\n20. 0.461907215007215\n21. 0.577774675324675\n22. 0.681033333333333\n23. 0.531433577533578\n24. 0.846385225885226\n25. 0.786795238095238\n26. 0.905457936507937\n27. 0.938673015873016\n28. 0.516453676878677\n29. 0.626481257631258\n30. 0.640150377400378\n31. 0.63495347985348\n32. 0.695756421356421\n33. 0.271838961038961\n34. 0.709228571428572\n35. 0.702262698412698\n36. 0.505207936507936\n37. 0.531402380952381\n38. 0.681780158730159\n39. 0.504721284271284\n40. 0.474046031746032\n41. 0.732080158730158\n42. 0.622136752136752\n43. 0.539236507936508\n44. 0.893160317460317\n45. 0.422708891108891\n46. 0.325338256188256\n47. 0.521945238095238\n48. 0.521149206349206\n49. 0.472207142857143\n50. 0.981492857142857\n51. 0.906424603174603\n52. 0.743688888888889\n53. 0.851051587301588\n54. 0.502744516594517\n55. 0.262538095238095\n56. 0.712144444444444\n57. 0.671992857142857\n58. 0.518690170940171\n59. 0.601017948717949\n60. 0.937355555555555\n61. 0.887538888888889\n62. 0.731896031746032\n63. 0.730421428571429\n64. 0.703314285714286\n65. 0.916836507936508\n66. 0.864348268398268\n67. 0.789061616161616\n68. 0.553385714285714\n69. 0.570180158730159\n70. 0.536660317460318\n71. 0.632815873015873\n72. 0.691459816207185\n73. 0.834188095238095\n74. 0.858404761904761\n75. 0.438089754689754\n76. 0.835488347763348\n77. 0.804288347763348\n78. 0.466011507936508\n79. 0.397729761904762\n80. 0.467036904761905\n81. 0.448124206349206\n82. 0.797895238095238\n83. 0.369473015873016\n84. 0.80563253968254\n85. 0.970392857142857\n86. 0.928287301587301\n87. 0.969826984126984\n88. 0.983140476190476\n89. 0.357992063492063\n90. 0.511392063492063\n91. 0.917814285714286\n92. 0.373842063492063\n93. 0.604902453102453\n94. 0.521338095238095\n95. 0.752358297258297\n96. 0.70682619047619\n97. 0.839950793650794\n98. 0.523692998667999\n99. 0.528168395493396\n100. 0.859322222222222\n101. 0.743658585858586\n102. 0.639124458874458\n103. 0.900343650793651\n104. 0.894138387635756\n105. 0.886500793650794\n106. 0.518755847953216\n107. 0.511377777777778\n108. 0.153843795093795\n109. 0.415119047619048\n110. 0.709538888888889\n111. 0.767264141414141\n112. 0.857169658119658\n113. 0.366344444444445\n114. 0.389292063492064\n115. 0.257188455988456\n116. 0.88297172096909\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.636726062826063</li><li>0.719253030303031</li><li>0.881211111111111</li><li>0.868673015873016</li><li>0.871745238095238</li><li>0.639620634920635</li><li>0.846961111111111</li><li>0.897896825396825</li><li>0.893107936507936</li><li>0.949614285714286</li><li>0.699337545787546</li><li>0.873749206349206</li><li>0.910895310245311</li><li>0.937971428571429</li><li>0.932174908424909</li><li>0.923783577533578</li><li>0.966528815628816</li><li>0.650757142857143</li><li>0.883881257631258</li><li>0.461907215007215</li><li>0.577774675324675</li><li>0.681033333333333</li><li>0.531433577533578</li><li>0.846385225885226</li><li>0.786795238095238</li><li>0.905457936507937</li><li>0.938673015873016</li><li>0.516453676878677</li><li>0.626481257631258</li><li>0.640150377400378</li><li>0.63495347985348</li><li>0.695756421356421</li><li>0.271838961038961</li><li>0.709228571428572</li><li>0.702262698412698</li><li>0.505207936507936</li><li>0.531402380952381</li><li>0.681780158730159</li><li>0.504721284271284</li><li>0.474046031746032</li><li>0.732080158730158</li><li>0.622136752136752</li><li>0.539236507936508</li><li>0.893160317460317</li><li>0.422708891108891</li><li>0.325338256188256</li><li>0.521945238095238</li><li>0.521149206349206</li><li>0.472207142857143</li><li>0.981492857142857</li><li>0.906424603174603</li><li>0.743688888888889</li><li>0.851051587301588</li><li>0.502744516594517</li><li>0.262538095238095</li><li>0.712144444444444</li><li>0.671992857142857</li><li>0.518690170940171</li><li>0.601017948717949</li><li>0.937355555555555</li><li>0.887538888888889</li><li>0.731896031746032</li><li>0.730421428571429</li><li>0.703314285714286</li><li>0.916836507936508</li><li>0.864348268398268</li><li>0.789061616161616</li><li>0.553385714285714</li><li>0.570180158730159</li><li>0.536660317460318</li><li>0.632815873015873</li><li>0.691459816207185</li><li>0.834188095238095</li><li>0.858404761904761</li><li>0.438089754689754</li><li>0.835488347763348</li><li>0.804288347763348</li><li>0.466011507936508</li><li>0.397729761904762</li><li>0.467036904761905</li><li>0.448124206349206</li><li>0.797895238095238</li><li>0.369473015873016</li><li>0.80563253968254</li><li>0.970392857142857</li><li>0.928287301587301</li><li>0.969826984126984</li><li>0.983140476190476</li><li>0.357992063492063</li><li>0.511392063492063</li><li>0.917814285714286</li><li>0.373842063492063</li><li>0.604902453102453</li><li>0.521338095238095</li><li>0.752358297258297</li><li>0.70682619047619</li><li>0.839950793650794</li><li>0.523692998667999</li><li>0.528168395493396</li><li>0.859322222222222</li><li>0.743658585858586</li><li>0.639124458874458</li><li>0.900343650793651</li><li>0.894138387635756</li><li>0.886500793650794</li><li>0.518755847953216</li><li>0.511377777777778</li><li>0.153843795093795</li><li>0.415119047619048</li><li>0.709538888888889</li><li>0.767264141414141</li><li>0.857169658119658</li><li>0.366344444444445</li><li>0.389292063492064</li><li>0.257188455988456</li><li>0.88297172096909</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01MWwfz2ZbSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "bcbae66c-0a95-4f02-9632-5f2b4cad6c8e"
      },
      "source": [
        "#install.packages(\"e1071\")\n",
        "library(e1071)\n",
        "## Part 2: Make predictions on test data using the trained model\n",
        "\n",
        "rf_probs <- predict(rf.evals.train, data.frame(evals.test))\n",
        "\n",
        "# Classification into low and high scorers\n",
        "\n",
        "rf_class <- ifelse(rf_probs$predictions[,2] > 0.5, 1,0) \n",
        "\n",
        "predicted_class = factor(rf_class)\n",
        "true_class = factor(target.test)\n",
        "\n",
        "cmat = confusionMatrix(predicted_class,true_class, positive = \"1\")\n",
        "cmat\n",
        "\n",
        "# Precision, recall, and F1\n",
        "precision = cmat$byClass[5]\n",
        "recall = cmat$byClass[6]\n",
        "F1 = cmat$byClass[7]\n",
        "Accuracy = cmat$overall[1]\n",
        "\n",
        "stats = c(Accuracy, precision,recall,F1)\n",
        "stats.rounded = round(stats,digits = 2)\n",
        "\n",
        "print(\n",
        "  paste(\"The performance stats are:\",\n",
        "        \"Accuracy:\",stats.rounded[1],\n",
        "         \"Precision:\",stats.rounded[2],\n",
        "         \"Recall:\", stats.rounded[3],\n",
        "          \"F1:\", stats.rounded[4]\n",
        "         )\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Confusion Matrix and Statistics\n",
              "\n",
              "          Reference\n",
              "Prediction  0  1\n",
              "         0 27 69\n",
              "         1 13  7\n",
              "                                          \n",
              "               Accuracy : 0.2931          \n",
              "                 95% CI : (0.2123, 0.3848)\n",
              "    No Information Rate : 0.6552          \n",
              "    P-Value [Acc > NIR] : 1               \n",
              "                                          \n",
              "                  Kappa : -0.1749         \n",
              "                                          \n",
              " Mcnemar's Test P-Value : 1.25e-09        \n",
              "                                          \n",
              "            Sensitivity : 0.09211         \n",
              "            Specificity : 0.67500         \n",
              "         Pos Pred Value : 0.35000         \n",
              "         Neg Pred Value : 0.28125         \n",
              "             Prevalence : 0.65517         \n",
              "         Detection Rate : 0.06034         \n",
              "   Detection Prevalence : 0.17241         \n",
              "      Balanced Accuracy : 0.38355         \n",
              "                                          \n",
              "       'Positive' Class : 1               \n",
              "                                          "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1] \"The performance stats are: Accuracy: 0.29 Precision: 0.35 Recall: 0.09 F1: 0.15\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P96MdxAyTThW",
        "colab_type": "text"
      },
      "source": [
        "# Question 2: Interpreting Results [25 Points]\n",
        "\n",
        "In words, please explain what the accuracy, precision and recall statistics that you just calculated mean. \n",
        "\n",
        "\n",
        "### Answer\n",
        "Accuracy tells you that the classifier correctly identified about 29% of the evaluations. Precision tells you that the probability that someone gets high teaching evaluations conditional on the classifier identifying them as having high evaluations is about 35%, thus we are not that confident in the results of our classifier. Finall, recall tells us that our classifier is a poor detector and only would identify about 9% of teachers with high teaching evaluations in a pool of teachers with high teaching evaluations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t46W8xi-T3oL",
        "colab_type": "text"
      },
      "source": [
        "# Question 3: Feature importance [25 points]\n",
        "\n",
        " Which features predict the excellence in teaching (the target) best?\n",
        "\n",
        "One of the best things about the random forests algorithm is that it allows us to understand which features contributed most to prediction success.\n",
        "\n",
        "Create a plot of the top 10 most important features for the model that you trained in Question 1. Do these results make sense? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1PvMbmFIG0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7bcd6c8a-0b21-42d5-ea83-cd4bf49d6a0a"
      },
      "source": [
        "# SCratch work\n",
        "\n",
        "head(importance.data)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   words         importance\n",
              "6  cls_perc_eval 16.065768 \n",
              "8  cls_students  12.356155 \n",
              "7  cls_did_eval  10.662828 \n",
              "5  age            9.494835 \n",
              "18 bty_avg        7.161413 \n",
              "14 bty_f2upper    6.645278 "
            ],
            "text/latex": "A data.frame: 6 × 2\n\\begin{tabular}{r|ll}\n  & words & importance\\\\\n  & <fct> & <dbl>\\\\\n\\hline\n\t6 & cls\\_perc\\_eval & 16.065768\\\\\n\t8 & cls\\_students  & 12.356155\\\\\n\t7 & cls\\_did\\_eval  & 10.662828\\\\\n\t5 & age           &  9.494835\\\\\n\t18 & bty\\_avg       &  7.161413\\\\\n\t14 & bty\\_f2upper   &  6.645278\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 6 × 2\n\n| <!--/--> | words &lt;fct&gt; | importance &lt;dbl&gt; |\n|---|---|---|\n| 6 | cls_perc_eval | 16.065768 |\n| 8 | cls_students  | 12.356155 |\n| 7 | cls_did_eval  | 10.662828 |\n| 5 | age           |  9.494835 |\n| 18 | bty_avg       |  7.161413 |\n| 14 | bty_f2upper   |  6.645278 |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A data.frame: 6 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>words</th><th scope=col>importance</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>6</th><td>cls_perc_eval</td><td>16.065768</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>cls_students </td><td>12.356155</td></tr>\n",
              "\t<tr><th scope=row>7</th><td>cls_did_eval </td><td>10.662828</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>age          </td><td> 9.494835</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>bty_avg      </td><td> 7.161413</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>bty_f2upper  </td><td> 6.645278</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kUWlmE-V65z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "28217d3d-11e7-47c6-a0d4-2e9410da0854"
      },
      "source": [
        "##### YOUR CODE HERE ###################################\n",
        "\n",
        "varimp = rf.evals.train$variable.importance\n",
        "\n",
        "# Extract the importance scores\n",
        "words<-names(varimp)\n",
        "importance<-as.vector(varimp)\n",
        "\n",
        "# Create a data frame with both\n",
        "importance.data = data.frame(words,importance)\n",
        "\n",
        "# Now we need to reorder the data frame in descending order\n",
        "importance.data = importance.data[order(-importance),]\n",
        "# Only look at the ten most important features of the model\n",
        "importtop10 = importance.data[1:10,]\n",
        "\n",
        "# Plot variable importance \n",
        "ggplot(importtop10, \n",
        "       aes(x=reorder(words,importance), y=importance,fill=importance))+ \n",
        "  geom_bar(stat=\"identity\", position=\"dodge\")+ coord_flip()+\n",
        "  ylab(\"Variable Importance\")+\n",
        "  xlab(\"\")+\n",
        "  ggtitle(\"Variable Importance Plot for Predicting High Evals\")+\n",
        "  guides(fill=F)+\n",
        "  scale_fill_gradient(low=\"red\", high=\"blue\")\n",
        "\n",
        "ggsave(\"evalvarimp.png\")\n",
        "##### YOUR CODE HERE ###################################"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving 6.67 x 6.67 in image\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nAJIg2AEAAEiCYAcAACAJgh0AAIAk/g9wvOrhRu99rQAAAABJRU5ErkJggg==",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 420,
              "height": 420
            },
            "text/plain": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    }
  ]
}